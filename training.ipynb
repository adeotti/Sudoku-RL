{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from environment import environment\n",
        "import random,sys,gc,warnings\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import gymnasium \n",
        "from puzzle import easyBoard\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import Categorical\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "from tqdm import tqdm\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\14385\\AppData\\Local\\Temp\\ipykernel_5832\\3212754417.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  b = F.one_hot(torch.tensor(easyBoard,dtype=torch.long),10).permute(-1,0,1)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "torch.Size([10, 9, 9])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b = F.one_hot(torch.tensor(easyBoard,dtype=torch.long),10).permute(-1,0,1)\n",
        "b.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# hypers\n",
        "batchSize = 10\n",
        "lr = 1e-4\n",
        "num_env = 3\n",
        "\n",
        "env = gymnasium.make(\"sudoku\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([4, 4, 6])"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class mask: # altering softmax output so x and y = {0,8} and value = {1,9}\n",
        "  def __init__(self):\n",
        "    self.newValue = -float(\"inf\")\n",
        "\n",
        "  def apply(self,tensor : torch.FloatTensor):\n",
        "    self.mask = torch.zeros_like(tensor,dtype=torch.bool)\n",
        "    self.mask[0,-1] = True\n",
        "    self.mask[1,-1] = True\n",
        "    self.mask[-1,0] = True\n",
        "    tensor = tensor.masked_fill(mask=self.mask,value=self.newValue)\n",
        "    return tensor\n",
        " \n",
        "class network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.representation = nn.Sequential(\n",
        "      nn.LazyConv2d(16,3,1,0),\n",
        "       nn.ReLU(),\n",
        "       nn.LazyConv2d(16,3,1,0),\n",
        "       nn.ReLU() # torch.Size([32, 5, 5])\n",
        "    )\n",
        "    self.prediction = nn.Sequential(\n",
        "      nn.Conv2d(16,1,1,1),\n",
        "      nn.ReLU(),\n",
        "      nn.Flatten(1),\n",
        "      nn.LazyLinear(27),\n",
        "      nn.ReLU() # torch.Size([1, 25])\n",
        "    )\n",
        "    self.mask = mask() # for the softmax distribution mask \n",
        "    self.policy = nn.LazyLinear(27) \n",
        "    self.value = nn.LazyLinear(1)\n",
        "\n",
        "    self.dynamic = nn.Sequential(\n",
        "      #######\n",
        "    )\n",
        "\n",
        "    self.optim = torch.optim.Adam(self.parameters(),lr=lr)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.representation(x)\n",
        "    x = self.prediction(x)\n",
        "\n",
        "    policy = self.policy(x)\n",
        "    softmax = F.softmax(self.mask.apply(policy.view(3,9)))  \n",
        "    value = self.value(x)\n",
        "    return softmax,value\n",
        "\n",
        "\n",
        "model = network()\n",
        "w,r = model.forward(b.to(torch.float32))\n",
        "\n",
        "Categorical(w).sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class mtcs:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class collector:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "        \n",
        "    def rollout(self):\n",
        "        pass\n",
        "\n",
        "    def sample(self):\n",
        "        pass\n",
        "\n",
        "    def clear_memory():\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def multiply(n=0,m=2,max=10,count = 0):\n",
        "    if count!= max:\n",
        "        print(f\"{n} X {m} = {n*m}\")\n",
        "        multiply(n=n+1,m=2,max=10,count=count+1)\n",
        "    \n",
        "multiply()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyO+jAeQFBuHrZI2VDVdbRVk",
      "include_colab_link": true,
      "mount_file_id": "1_lC2ngW2272azpP9OPB1SB9FRya0fTmE",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
